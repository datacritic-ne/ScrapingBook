{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654c4571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logo-jpg', <http.client.HTTPMessage at 0x7f5c35800990>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "#from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "imageLocation = bs.find('img', {'alt': 'python-logo'})['src']\n",
    "urlretrieve (imageLocation, 'logo-jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96849c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pythonscraping.com/wp-includes/js/jquery/jquery.min.js?ver=3.7.1\n",
      "https://pythonscraping.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.4.1\n",
      "https://pythonscraping.com/wp-content/plugins/pagelayer/js/combined.js?ver=1.7.5\n",
      "https://pythonscraping.com/wp-content/plugins/email-capture-lead-generation//js/eclg-public.js?ver=1.0.1\n",
      "https://www.googletagmanager.com/gtag/js?id=GT-TNFZZK6\n",
      "https://pythonscraping.com/wp-content/uploads/2023/04/python-logo-e1681354047443.png\n",
      "https://pythonscraping.com/wp-content/uploads/2021/08/home1.jpg\n",
      "https://pythonscraping.com/wp-content/uploads/2021/08/logo01-e1681353135199.png\n",
      "https://pythonscraping.com/wp-content/plugins/email-capture-lead-generation//images/ajax_loader.gif\n",
      "https://pythonscraping.com/wp-content/plugins/contact-form-7/includes/swv/js/index.js?ver=5.7.7\n",
      "https://pythonscraping.com/wp-content/plugins/contact-form-7/includes/js/index.js?ver=5.7.7\n",
      "https://pythonscraping.com/wp-content/themes/popularfx/js/navigation.js?ver=1.2.0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: DON'T RUN THIS!\n",
    "\n",
    "import os\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "downloadDir = 'downloaded'\n",
    "baseUrl = 'https://pythonscraping.com/'\n",
    "baseNetloc = urlparse(baseUrl).netloc\n",
    "\n",
    "def getAbsoluteURL(source):\n",
    "    if urlparse(baseUrl).netloc == '':\n",
    "        return baseUrl + source\n",
    "    return source\n",
    "\n",
    "def getDownloadPath(fileUrl):\n",
    "    parsed = urlparse(fileUrl)\n",
    "    netloc = parsed.netloc.strip('/')\n",
    "    path = parsed.path.strip('/')\n",
    "    localfile = f'{downloadDir}/{netloc}/{path}'\n",
    "    \n",
    "    localpath = '/'.join(localfile.split('/')[:-1]) # remove the filename from the path to make the directory structure lead to it\n",
    "    if not os.path.exists(localpath):\n",
    "        os.makedirs(localpath)\n",
    "    return localfile\n",
    "\n",
    "html = urlopen(baseUrl)\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "downloadList = bs.findAll(src=True)\n",
    "\n",
    "for download in downloadList:\n",
    "    fileUrl = getAbsoluteURL(download['src'])\n",
    "    if fileUrl is not None:\n",
    "        try:\n",
    "            urlretrieve(fileUrl, getDownloadPath(fileUrl))\n",
    "            print(fileUrl)\n",
    "        except Exception as e:\n",
    "            print(f'Could not retrieve {fileUrl} Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb1fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = open('test.csv', 'w+')\n",
    "\n",
    "try:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(('number', 'number plus 2', 'number times 2'))\n",
    "    for i in range(10):\n",
    "        writer.writerow((i, i+2, i*2))\n",
    "finally:\n",
    "    csvfile.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa65b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "table = bs.find('table',{'class':'wikitable'})\n",
    "rows = table.findAll('tr')\n",
    "csvFile = open('countries.csv', 'w+')\n",
    "writer = csv.writer(csvFile)\n",
    "\n",
    "try:\n",
    "    for row in rows:\n",
    "        csvRow = []\n",
    "        for cell in row.findAll(['td', 'th']):\n",
    "            csvRow.append(cell.get_text().strip())\n",
    "        writer.writerow(csvRow)\n",
    "finally:\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7975b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
